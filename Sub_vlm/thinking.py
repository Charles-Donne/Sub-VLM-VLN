"""
LLMè§„åˆ’ä¸æ€è€ƒæ¨¡å—
è´Ÿè´£å­ä»»åŠ¡ç”Ÿæˆã€å®ŒæˆéªŒè¯å’Œå¯¼èˆªè§„åˆ’
"""
import json
import requests
import base64
from typing import Dict, List, Tuple, Optional
from Sub_vlm.llm_config import LLMConfig
from Sub_vlm.prompts import (
    get_initial_planning_prompt,
    get_verification_prompt,
    get_task_completion_prompt
)


class SubTask:
    """å­ä»»åŠ¡æ•°æ®ç»“æ„"""
    
    def __init__(self, description: str, planning_hints: str, completion_criteria: str):
        """
        Args:
            description: å­ä»»åŠ¡æè¿°
            planning_hints: è§„åˆ’æç¤ºï¼ˆè¾…åŠ©æ€è€ƒï¼‰
            completion_criteria: å®Œæˆåˆ¤åˆ«æ ‡å‡†
        """
        self.description = description
        self.planning_hints = planning_hints
        self.completion_criteria = completion_criteria
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "description": self.description,
            "planning_hints": self.planning_hints,
            "completion_criteria": self.completion_criteria
        }
    
    def __repr__(self):
        return f"SubTask(description='{self.description[:50]}...')"


class LLMPlanner:
    """LLMè§„åˆ’å™¨ - è´Ÿè´£å­ä»»åŠ¡ç”Ÿæˆå’ŒéªŒè¯"""
    
    def __init__(self, config_path="llm_config.yaml"):
        """
        åˆå§‹åŒ–è§„åˆ’å™¨
        
        Args:
            config_path: LLMé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = LLMConfig(config_path)
        print(f"âœ“ LLMè§„åˆ’å™¨åˆå§‹åŒ–å®Œæˆ: {self.config}")
    
    def encode_image_base64(self, image_path: str) -> str:
        """
        å°†å›¾åƒç¼–ç ä¸ºbase64
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            base64ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²
        """
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode('utf-8')
    
    def _build_initial_planning_prompt(self, instruction: str, direction_names: List[str]) -> str:
        """
        æ„å»ºåˆå§‹è§„åˆ’promptï¼ˆä»»åŠ¡å¼€å§‹æ—¶ï¼‰
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            direction_names: æ–¹å‘åç§°åˆ—è¡¨ï¼ˆå¯¹åº”8å¼ å›¾ç‰‡ï¼‰
            
        Returns:
            promptæ–‡æœ¬
        """
        return get_initial_planning_prompt(instruction, direction_names)
    
    def _build_verification_prompt(self, 
                                   instruction: str,
                                   subtask: SubTask,
                                   direction_names: List[str]) -> str:
        """
        æ„å»ºéªŒè¯promptï¼ˆæ£€æŸ¥å­ä»»åŠ¡æ˜¯å¦å®Œæˆï¼‰
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            subtask: å½“å‰å­ä»»åŠ¡
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            promptæ–‡æœ¬
        """
        return get_verification_prompt(
            instruction,
            subtask.description,
            subtask.completion_criteria,
            subtask.planning_hints,
            direction_names
        )
    
    def _build_task_completion_prompt(self,
                                     instruction: str,
                                     direction_names: List[str]) -> str:
        """
        æ„å»ºä»»åŠ¡å®Œæˆæ£€æŸ¥prompt
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            promptæ–‡æœ¬
        """
        return get_task_completion_prompt(instruction, direction_names)
    
    def _call_llm_api(self, 
                     prompt: str, 
                     image_paths: List[str]) -> Optional[Dict]:
        """
        è°ƒç”¨LLM API
        
        Args:
            prompt: æ–‡æœ¬prompt
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            APIå“åº”çš„JSONæ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = [{"type": "text", "text": prompt}]
            
            # æ·»åŠ å›¾åƒ
            for img_path in image_paths:
                img_base64 = self.encode_image_base64(img_path)
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}"
                    }
                })
            
            # æ„å»ºè¯·æ±‚
            payload = {
                "model": self.config.model,
                "messages": [
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                "temperature": self.config.temperature,
                "max_tokens": self.config.max_tokens
            }
            
            # å‘é€è¯·æ±‚
            print(f"\nğŸ¤– æ­£åœ¨è°ƒç”¨LLM API ({self.config.model})...")
            response = requests.post(
                f"{self.config.base_url}/chat/completions",
                headers=self.config.get_headers(),
                json=payload,
                timeout=self.config.timeout
            )
            
            response.raise_for_status()
            
            # è§£æå“åº”
            result = response.json()
            content_text = result['choices'][0]['message']['content']
            
            # å°è¯•è§£æJSON
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            content_text = content_text.strip()
            if content_text.startswith("```json"):
                content_text = content_text[7:]
            if content_text.startswith("```"):
                content_text = content_text[3:]
            if content_text.endswith("```"):
                content_text = content_text[:-3]
            content_text = content_text.strip()
            
            # å°è¯•è§£æJSON
            try:
                parsed_json = json.loads(content_text)
            except json.JSONDecodeError as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                print(f"âš ï¸ åˆæ¬¡JSONè§£æå¤±è´¥: {e}")
                print(f"ğŸ“ å°è¯•ä¿®å¤JSONæ ¼å¼...")
                
                # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                brace_count = 0
                json_end = -1
                for i, char in enumerate(content_text):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
                
                if json_end > 0:
                    content_text = content_text[:json_end]
                    try:
                        parsed_json = json.loads(content_text)
                        print("âœ“ JSONä¿®å¤æˆåŠŸ")
                    except json.JSONDecodeError:
                        print(f"âœ— JSONä¿®å¤å¤±è´¥")
                        print(f"åŸå§‹å“åº”: {content_text[:500]}...")
                        return None
                else:
                    print(f"âœ— æ— æ³•æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡")
                    print(f"åŸå§‹å“åº”: {content_text[:500]}...")
                    return None
            
            print("âœ“ LLMå“åº”è§£ææˆåŠŸ")
            return parsed_json
            
        except requests.exceptions.RequestException as e:
            print(f"âœ— APIè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"âœ— æœªçŸ¥é”™è¯¯: {e}")
            return None
    
    def generate_initial_subtask(self,
                                instruction: str,
                                observation_images: List[str],
                                direction_names: List[str]) -> Optional[SubTask]:
        """
        ç”Ÿæˆåˆå§‹å­ä»»åŠ¡ï¼ˆä»»åŠ¡å¼€å§‹æ—¶ï¼‰
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            observation_images: 8ä¸ªæ–¹å‘çš„å›¾åƒè·¯å¾„åˆ—è¡¨
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            SubTaskå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        prompt = self._build_initial_planning_prompt(instruction, direction_names)
        
        response = self._call_llm_api(prompt, observation_images)
        
        if response is None:
            return None
        
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['subtask_instruction', 'planning_hints', 'completion_criteria']
            missing_fields = [field for field in required_fields if field not in response]
            
            if missing_fields:
                print(f"âœ— å“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}")
                print(f"âœ— å®é™…æ”¶åˆ°çš„å­—æ®µ: {list(response.keys())}")
                return None
            
            subtask = SubTask(
                description=response['subtask_instruction'],
                planning_hints=response['planning_hints'],
                completion_criteria=response['completion_criteria']
            )
            
            print(f"\nğŸ“‹ ç”Ÿæˆçš„å­ä»»åŠ¡:")
            print(f"  å½“å‰ä½ç½®: {response.get('current_location', 'N/A')}")
            print(f"  æŒ‡ä»¤åºåˆ—: {response.get('instruction_sequence', 'N/A')}")
            print(f"  å­ä»»åŠ¡ç›®çš„åœ°: {response.get('subtask_destination', 'N/A')}")
            print(f"  å­ä»»åŠ¡æŒ‡ä»¤: {subtask.description}")
            print(f"  è§„åˆ’æç¤º: {subtask.planning_hints}")
            print(f"  å®Œæˆæ ‡å‡†: {subtask.completion_criteria}")
            if 'reasoning' in response:
                print(f"  æ¨ç†è¿‡ç¨‹: {response['reasoning']}")
            
            return subtask
            
        except KeyError as e:
            print(f"âœ— å­—æ®µè®¿é—®é”™è¯¯: {e}")
            print(f"âœ— å®é™…æ”¶åˆ°çš„å­—æ®µ: {list(response.keys()) if response else 'None'}")
            return None
        except Exception as e:
            print(f"âœ— å­ä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def verify_and_plan_next(self,
                            instruction: str,
                            current_subtask: SubTask,
                            observation_images: List[str],
                            direction_names: List[str]) -> Tuple[bool, Optional[SubTask], Optional[str]]:
        """
        éªŒè¯å½“å‰å­ä»»åŠ¡å¹¶è§„åˆ’ä¸‹ä¸€ä¸ª
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            current_subtask: å½“å‰å­ä»»åŠ¡
            observation_images: 8ä¸ªæ–¹å‘çš„å›¾åƒè·¯å¾„åˆ—è¡¨
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            (is_completed, next_subtask, advice)
            - is_completed: å½“å‰å­ä»»åŠ¡æ˜¯å¦å®Œæˆ
            - next_subtask: ä¸‹ä¸€ä¸ªå­ä»»åŠ¡ï¼ˆå¦‚æœå½“å‰å·²å®Œæˆï¼‰
            - advice: ç»§ç»­å®Œæˆçš„å»ºè®®ï¼ˆå¦‚æœæœªå®Œæˆï¼‰
        """
        prompt = self._build_verification_prompt(
            instruction, current_subtask, direction_names
        )
        
        response = self._call_llm_api(prompt, observation_images)
        
        if response is None:
            return False, None, "APIè°ƒç”¨å¤±è´¥ï¼Œæ— æ³•éªŒè¯"
        
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            if 'is_completed' not in response:
                print(f"âœ— å“åº”ç¼ºå°‘ 'is_completed' å­—æ®µ")
                print(f"âœ— å®é™…æ”¶åˆ°çš„å­—æ®µ: {list(response.keys())}")
                return False, None, "å“åº”æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘is_completedå­—æ®µ"
            
            is_completed = response['is_completed']
            analysis = response.get('completion_analysis', 'æ— åˆ†æä¿¡æ¯')
            
            print(f"\nğŸ” å­ä»»åŠ¡éªŒè¯ç»“æœ:")
            print(f"  å®ŒæˆçŠ¶æ€: {'âœ“ å·²å®Œæˆ' if is_completed else 'âœ— æœªå®Œæˆ'}")
            print(f"  åˆ†æ: {analysis}")
            
            if is_completed:
                # éªŒè¯ next_subtask å­—æ®µ
                if 'next_subtask' not in response:
                    print(f"âœ— å·²å®Œæˆä½†ç¼ºå°‘ 'next_subtask' å­—æ®µ")
                    return False, None, "å“åº”æ ¼å¼é”™è¯¯ï¼šå·²å®Œæˆä½†æ— ä¸‹ä¸€ä¸ªå­ä»»åŠ¡"
                
                next_data = response['next_subtask']
                required_subtask_fields = ['subtask_instruction', 'planning_hints', 'completion_criteria']
                missing_fields = [field for field in required_subtask_fields if field not in next_data]
                
                if missing_fields:
                    print(f"âœ— next_subtask ç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
                    return False, None, f"next_subtaskæ ¼å¼é”™è¯¯ï¼šç¼ºå°‘{', '.join(missing_fields)}"
                
                next_subtask = SubTask(
                    description=next_data['subtask_instruction'],
                    planning_hints=next_data['planning_hints'],
                    completion_criteria=next_data['completion_criteria']
                )
                
                print(f"\nğŸ“‹ ä¸‹ä¸€ä¸ªå­ä»»åŠ¡:")
                print(f"  æè¿°: {next_subtask.description}")
                print(f"  æç¤º: {next_subtask.planning_hints}")
                print(f"  æ ‡å‡†: {next_subtask.completion_criteria}")
                
                return True, next_subtask, None
            else:
                advice = response.get('continuation_advice', 'ç»§ç»­æŒ‰è®¡åˆ’æ‰§è¡Œ')
                print(f"  å»ºè®®: {advice}")
                return False, None, advice
                
        except KeyError as e:
            print(f"âœ— å­—æ®µè®¿é—®é”™è¯¯: {e}")
            print(f"âœ— å®é™…æ”¶åˆ°çš„å­—æ®µ: {list(response.keys()) if response else 'None'}")
            return False, None, f"å­—æ®µè®¿é—®é”™è¯¯: {e}"
        except Exception as e:
            print(f"âœ— éªŒè¯å¤„ç†å¤±è´¥: {e}")
            return False, None, f"å¤„ç†å¼‚å¸¸: {e}"
    
    def check_task_completion(self,
                             instruction: str,
                             observation_images: List[str],
                             direction_names: List[str]) -> Tuple[bool, float, str]:
        """
        æ£€æŸ¥æ•´ä¸ªä»»åŠ¡æ˜¯å¦å®Œæˆ
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            observation_images: 8ä¸ªæ–¹å‘çš„å›¾åƒè·¯å¾„åˆ—è¡¨
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            (is_completed, confidence, analysis)
        """
        prompt = self._build_task_completion_prompt(instruction, direction_names)
        
        response = self._call_llm_api(prompt, observation_images)
        
        if response is None:
            return False, 0.0, "APIè°ƒç”¨å¤±è´¥"
        
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['task_completed', 'confidence', 'analysis']
            missing_fields = [field for field in required_fields if field not in response]
            
            if missing_fields:
                print(f"âœ— å“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}")
                print(f"âœ— å®é™…æ”¶åˆ°çš„å­—æ®µ: {list(response.keys())}")
                return False, 0.0, f"å“åº”æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘{', '.join(missing_fields)}"
            
            is_completed = response['task_completed']
            confidence = float(response['confidence'])  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            analysis = response['analysis']
            
            # éªŒè¯ confidence èŒƒå›´
            if not (0.0 <= confidence <= 1.0):
                print(f"âš ï¸ ç½®ä¿¡åº¦è¶…å‡ºèŒƒå›´: {confidence}ï¼Œå°†é™åˆ¶åœ¨[0.0, 1.0]")
                confidence = max(0.0, min(1.0, confidence))
            
            print(f"\nğŸ¯ ä»»åŠ¡å®Œæˆæ£€æŸ¥:")
            print(f"  çŠ¶æ€: {'âœ“ å·²å®Œæˆ' if is_completed else 'âœ— æœªå®Œæˆ'}")
            print(f"  ç½®ä¿¡åº¦: {confidence:.2%}")
            print(f"  åˆ†æ: {analysis}")
            
            if not is_completed and 'recommendation' in response and response['recommendation']:
                print(f"  å»ºè®®: {response['recommendation']}")
            
            return is_completed, confidence, analysis
            
        except (KeyError, ValueError, TypeError) as e:
            print(f"âœ— å­—æ®µè§£æé”™è¯¯: {e}")
            print(f"âœ— å®é™…æ”¶åˆ°çš„å­—æ®µ: {list(response.keys()) if response else 'None'}")
            return False, 0.0, f"å­—æ®µè§£æé”™è¯¯: {e}"
        except Exception as e:
            print(f"âœ— ä»»åŠ¡æ£€æŸ¥å¤±è´¥: {e}")
            return False, 0.0, f"å¤„ç†å¼‚å¸¸: {e}"
