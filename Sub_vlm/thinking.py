"""
LLM Planning and Reasoning Module
Responsible for subtask generation, completion verification, and navigation planning

æ¨¡å—æ¶æ„:
1. åˆå§‹å­ä»»åŠ¡ç”Ÿæˆæ¨¡å— (generate_initial_subtask)
   - åœ¨ä»»åŠ¡å¼€å§‹æ—¶åˆ†æç¯å¢ƒ,ç”Ÿæˆç¬¬ä¸€ä¸ªå­ä»»åŠ¡
   - è¾“å‡º: responseå­—å…¸(åŒ…å«subtask_destination, subtask_instruction, planning_hints, completion_criteria)
   
2. éªŒè¯+å†è§„åˆ’æ¨¡å— (verify_and_replan)
   - æ¥æ”¶ä¸Šä¸€æ­¥çš„å­ä»»åŠ¡å­—å…¸(ç›®çš„åœ°ã€æŒ‡ä»¤ã€å®Œæˆçº¦æŸæ¡ä»¶)
   - éªŒè¯æ˜¯å¦å®Œæˆå­ä»»åŠ¡
   - å¦‚æœå®Œæˆ: ç”Ÿæˆä¸‹ä¸€ä¸ªå­ä»»åŠ¡
   - å¦‚æœæœªå®Œæˆ: ä¿®æ”¹å½“å‰å­ä»»åŠ¡æŒ‡ä»¤,ä¿æŒç›®çš„åœ°ä¸å˜
   - è¾“å‡º: (responseå­—å…¸, is_completed)
   
3. å…¨å±€ä»»åŠ¡å®Œæˆæ£€æŸ¥ (check_task_completion)
   - æ£€æŸ¥æ•´ä¸ªå¯¼èˆªä»»åŠ¡æ˜¯å¦å®Œæˆ
   - è¾“å‡º: (responseå­—å…¸, is_completed, confidence, analysis)

ä½¿ç”¨æµç¨‹:
Step 1: generate_initial_subtask() -> responseå­—å…¸
Step 2: æ‰§è¡ŒåŠ¨ä½œ...
Step 3: verify_and_replan() -> (responseå­—å…¸, is_completed)
Step 4a: å¦‚æœcompleted=True -> responseæ˜¯æ–°çš„å­ä»»åŠ¡,å›åˆ°Step 2
Step 4b: å¦‚æœcompleted=False -> responseæ˜¯ä¿®æ”¹åçš„å½“å‰å­ä»»åŠ¡,å›åˆ°Step 2
"""
import json
import requests
import base64
import os
from typing import Dict, List, Tuple, Optional
from Sub_vlm.llm_config import LLMConfig
from Sub_vlm.prompts import (
    get_initial_planning_prompt,
    get_verification_replanning_prompt,
    get_task_completion_prompt
)


class LLMPlanner:
    """LLMè§„åˆ’å™¨ - è´Ÿè´£å­ä»»åŠ¡ç”Ÿæˆå’ŒéªŒè¯"""
    
    def __init__(self, config_path="llm_config.yaml", action_space: str = None):
        """
        åˆå§‹åŒ–è§„åˆ’å™¨
        
        Args:
            config_path: LLMé…ç½®æ–‡ä»¶è·¯å¾„
            action_space: åŠ¨ä½œç©ºé—´æè¿°,å¦‚ "MOVE_FORWARD (0.25m), TURN_LEFT (45Â°), TURN_RIGHT (45Â°), STOP"
        """
        self.config = LLMConfig(config_path)
        self.action_space = action_space or "MOVE_FORWARD, TURN_LEFT, TURN_RIGHT, STOP"
        print(f"âœ“ LLM Planner initialized: {self.config}")
        print(f"âœ“ Action space: {self.action_space}")
    
    def encode_image_base64(self, image_path: str) -> str:
        """ç¼–ç å›¾åƒä¸ºbase64"""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode('utf-8')
    
    def _build_initial_planning_prompt(self, instruction: str, direction_names: List[str]) -> str:
        """æ„å»ºåˆå§‹è§„åˆ’prompt"""
        return get_initial_planning_prompt(instruction, direction_names, self.action_space)
    
    def _build_verification_replanning_prompt(self, instruction: str, current_subtask: Dict, direction_names: List[str]) -> str:
        """æ„å»ºéªŒè¯+å†è§„åˆ’prompt"""
        return get_verification_replanning_prompt(
            instruction,
            current_subtask['subtask_destination'],
            current_subtask['subtask_instruction'],
            current_subtask['completion_criteria'],
            direction_names,
            self.action_space
        )
    
    def _build_task_completion_prompt(self, instruction: str, direction_names: List[str]) -> str:
        """æ„å»ºä»»åŠ¡å®Œæˆæ£€æŸ¥prompt"""
        return get_task_completion_prompt(instruction, direction_names)
    
    def _call_llm_api(self, prompt: str, image_paths: List[str]) -> Optional[Dict]:
        """
        è°ƒç”¨LLM API
        
        Args:
            prompt: æ–‡æœ¬æç¤º
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            APIå“åº”çš„JSONæ•°æ®,å¤±è´¥æ—¶è¿”å›None
        """
        try:
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = [{"type": "text", "text": prompt}]
            
            # æ·»åŠ å›¾åƒ
            for img_path in image_paths:
                img_base64 = self.encode_image_base64(img_path)
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}"
                    }
                })
            
            # æ„å»ºè¯·æ±‚
            payload = {
                "model": self.config.model,
                "messages": [{"role": "user", "content": content}],
                "temperature": self.config.temperature,
                "max_tokens": self.config.max_tokens
            }
            
            # å‘é€è¯·æ±‚
            print(f"\nğŸ¤– Calling LLM API ({self.config.model})...")
            response = requests.post(
                f"{self.config.base_url}/chat/completions",
                headers=self.config.get_headers(),
                json=payload,
                timeout=self.config.timeout
            )
            response.raise_for_status()
            
            # è§£æå“åº”
            result = response.json()
            content_text = result['choices'][0]['message']['content']
            
            # æ¸…ç†JSONæ ‡è®°
            content_text = content_text.strip()
            if content_text.startswith("```json"):
                content_text = content_text[7:]
            if content_text.startswith("```"):
                content_text = content_text[3:]
            if content_text.endswith("```"):
                content_text = content_text[:-3]
            content_text = content_text.strip()
            
            # è§£æJSON
            try:
                parsed_json = json.loads(content_text)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ Initial JSON parsing failed: {e}")
                print(f"ğŸ“ Attempting to fix JSON format...")
                
                # å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡
                brace_count = 0
                json_end = -1
                for i, char in enumerate(content_text):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
                
                if json_end > 0:
                    content_text = content_text[:json_end]
                    try:
                        parsed_json = json.loads(content_text)
                        print("âœ“ JSON repair successful")
                    except json.JSONDecodeError:
                        print(f"âœ— JSON repair failed")
                        print(f"Raw response: {content_text[:500]}...")
                        return None
                else:
                    print(f"âœ— Cannot find complete JSON object")
                    print(f"Raw response: {content_text[:500]}...")
                    return None
            
            print("âœ“ LLM response parsed successfully")
            return parsed_json
            
        except requests.exceptions.RequestException as e:
            print(f"âœ— API request failed: {e}")
            return None
        except Exception as e:
            print(f"âœ— Unknown error: {e}")
            return None
    
    def generate_initial_subtask(self,
                                instruction: str,
                                observation_images: List[str],
                                direction_names: List[str]) -> Optional[Dict]:
        """
        ç”Ÿæˆåˆå§‹å­ä»»åŠ¡(ä»»åŠ¡å¼€å§‹æ—¶)
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            observation_images: 8æ–¹å‘å›¾åƒè·¯å¾„åˆ—è¡¨
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            response_dict: å®Œæ•´çš„LLMå“åº”JSONå­—å…¸,å¤±è´¥æ—¶è¿”å›None
        """
        prompt = self._build_initial_planning_prompt(instruction, direction_names)
        response = self._call_llm_api(prompt, observation_images)
        
        if response is None:
            return None
        
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['subtask_destination', 'subtask_instruction', 'planning_hints', 'completion_criteria']
            missing_fields = [field for field in required_fields if field not in response]
            
            if missing_fields:
                print(f"âœ— Response missing required fields: {', '.join(missing_fields)}")
                print(f"âœ— Actual fields received: {list(response.keys())}")
                return None
            
            return response
            
        except Exception as e:
            print(f"âœ— Subtask parsing failed: {e}")
            return None
    
    def verify_and_replan(self,
                         instruction: str,
                         current_subtask: Dict,
                         observation_images: List[str],
                         direction_names: List[str]) -> Tuple[Optional[Dict], bool]:
        """
        éªŒè¯+å†è§„åˆ’æ¨¡å— - éªŒè¯å­ä»»åŠ¡å®Œæˆå¹¶è§„åˆ’ä¸‹ä¸€æ­¥
        
        æ­¤æ¨¡å—è´Ÿè´£:
        1. éªŒè¯å½“å‰å­ä»»åŠ¡æ˜¯å¦å®Œæˆ(åŸºäºå®Œæˆçº¦æŸæ¡ä»¶)
        2. å¦‚æœå®Œæˆ: ç”Ÿæˆä¸‹ä¸€ä¸ªå­ä»»åŠ¡
        3. å¦‚æœæœªå®Œæˆ: ä¿®æ”¹å½“å‰å­ä»»åŠ¡æŒ‡ä»¤,ä¿æŒç›®çš„åœ°ä¸å˜
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤(å…¨å±€ä»»åŠ¡)
            current_subtask: å½“å‰å­ä»»åŠ¡å­—å…¸(åŒ…å«ç›®çš„åœ°ã€æŒ‡ä»¤ã€å®Œæˆçº¦æŸæ¡ä»¶)
            observation_images: 8æ–¹å‘å›¾åƒè·¯å¾„åˆ—è¡¨
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            (response_dict, is_completed)
            - response_dict: å®Œæ•´çš„LLMå“åº”JSONå­—å…¸,å¤±è´¥æ—¶è¿”å›None
            - is_completed: æ˜¯å¦å®Œæˆå½“å‰å­ä»»åŠ¡
        """
        prompt = self._build_verification_replanning_prompt(instruction, current_subtask, direction_names)
        response = self._call_llm_api(prompt, observation_images)
        
        if response is None:
            return None, False
        
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['is_completed', 'subtask_destination', 'subtask_instruction', 
                             'planning_hints', 'completion_criteria']
            missing_fields = [field for field in required_fields if field not in response]
            
            if missing_fields:
                print(f"âœ— Response missing required fields: {', '.join(missing_fields)}")
                print(f"âœ— Actual fields received: {list(response.keys())}")
                return None, False
            
            # æå–éªŒè¯ç»“æœ
            is_completed = response['is_completed']
            
            return response, is_completed
                
        except Exception as e:
            print(f"âœ— Verification and replanning failed: {e}")
            return None, False
    
    def check_task_completion(self,
                             instruction: str,
                             observation_images: List[str],
                             direction_names: List[str]) -> Tuple[Optional[Dict], bool, float, str]:
        """
        æ£€æŸ¥æ•´ä¸ªä»»åŠ¡æ˜¯å¦å®Œæˆ
        
        Args:
            instruction: å®Œæ•´å¯¼èˆªæŒ‡ä»¤
            observation_images: 8æ–¹å‘å›¾åƒè·¯å¾„åˆ—è¡¨
            direction_names: æ–¹å‘åç§°åˆ—è¡¨
            
        Returns:
            (response_dict, is_completed, confidence, analysis)
            - response_dict: å®Œæ•´çš„LLMå“åº”JSONå­—å…¸
            - is_completed: æ˜¯å¦å®Œæˆä»»åŠ¡
            - confidence: å®Œæˆçš„ç½®ä¿¡åº¦(0-1)
            - analysis: åˆ†æè¯´æ˜
        """
        prompt = self._build_task_completion_prompt(instruction, direction_names)
        response = self._call_llm_api(prompt, observation_images)
        
        if response is None:
            return None, False, 0.0, "API call failed"
        
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['task_completed', 'confidence', 'analysis']
            missing_fields = [field for field in required_fields if field not in response]
            
            if missing_fields:
                print(f"âœ— Response missing required fields: {', '.join(missing_fields)}")
                print(f"âœ— Actual fields received: {list(response.keys())}")
                return response, False, 0.0, f"Response format error: missing {', '.join(missing_fields)}"
            
            is_completed = response['task_completed']
            confidence = float(response['confidence'])
            analysis = response['analysis']
            
            # éªŒè¯confidenceèŒƒå›´
            if not (0.0 <= confidence <= 1.0):
                print(f"âš ï¸ Confidence out of range: {confidence}, clamping to [0.0, 1.0]")
                confidence = max(0.0, min(1.0, confidence))
            
            return response, is_completed, confidence, analysis
            
        except (KeyError, ValueError, TypeError) as e:
            print(f"âœ— Field parsing error: {e}")
            print(f"âœ— Actual fields received: {list(response.keys()) if response else 'None'}")
            return response, False, 0.0, f"Field parsing error: {e}"
        except Exception as e:
            print(f"âœ— Task check failed: {e}")
            return response, False, 0.0, f"Processing exception: {e}"
