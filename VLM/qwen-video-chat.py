import torch
import os
import re
from pathlib import Path
from transformers import AutoModelForImageTextToText, AutoProcessor
from PIL import Image

def natural_sort_key(text):
    """è‡ªç„¶æ’åºï¼šæ­£ç¡®å¤„ç†æ•°å­—ï¼ˆ1, 2, 10 è€Œä¸æ˜¯ 1, 10, 2ï¼‰"""
    return [int(c) if c.isdigit() else c.lower() for c in re.split('([0-9]+)', str(text))]

# æœ¬åœ°æ¨¡å‹è·¯å¾„
MODEL_PATH = "/root/autodl-tmp/Qwen3-VL-8B-Instruct"

# å›ºå®šçš„å›¾åƒå¸§ç›®å½•ï¼ˆä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰
FRAMES_DIRECTORY = "/root/autodl-tmp/video_frames"

# å†å²ç®¡ç†é…ç½®
MAX_HISTORY_TURNS = 5   # å›¾åƒè¾ƒå¤šï¼Œå‡å°‘ä¿ç•™è½®æ•°
MAX_TOKENS = 6144       # å›¾åƒå ç”¨tokenå¤šï¼Œå¢åŠ é™åˆ¶
MAX_FRAMES = 8          # å•æ¬¡æœ€å¤šå¤„ç†8å¸§å›¾åƒ

# 1. åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
model = AutoModelForImageTextToText.from_pretrained(
    MODEL_PATH,
    device_map="auto",
    dtype="auto",
)
processor = AutoProcessor.from_pretrained(MODEL_PATH)
print("æ¨¡å‹åŠ è½½å®Œæˆ!")

# è‡ªåŠ¨åŠ è½½å›¾åƒå¸§
print("\næ­£åœ¨ä»å›ºå®šç›®å½•åŠ è½½å›¾åƒå¸§...")
print(f"ç›®å½•: {FRAMES_DIRECTORY}")

# å¯¹è¯å†å²å’Œå›¾åƒå¸§
conversation_history = []
current_frames = []  # å­˜å‚¨å½“å‰åŠ è½½çš„å›¾åƒè·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰

def load_frames_from_directory(directory_path):
    """ä»ç›®å½•åŠ è½½å›¾åƒå¸§ï¼ŒæŒ‰æ–‡ä»¶åæ’åº"""
    global current_frames
    
    if not os.path.exists(directory_path):
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        return False
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'}
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = []
    for file in Path(directory_path).iterdir():
        if file.suffix.lower() in image_extensions:
            image_files.append(file)
    
    if not image_files:
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return False
    
    # æŒ‰æ–‡ä»¶åè‡ªç„¶æ’åºï¼ˆæ­£ç¡®å¤„ç†æ•°å­—ï¼š1, 2, 10 è€Œä¸æ˜¯ 1, 10, 2ï¼‰
    image_files.sort(key=lambda x: natural_sort_key(x.name))
    
    # é™åˆ¶å¸§æ•°
    if len(image_files) > MAX_FRAMES:
        print(f"âš ï¸  è­¦å‘Š: å‘ç° {len(image_files)} å¸§ï¼ŒåªåŠ è½½æœ€è¿‘çš„ {MAX_FRAMES} å¸§")
        image_files = image_files[-MAX_FRAMES:]
    
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„å­—ç¬¦ä¸²
    current_frames = [str(file.absolute()) for file in image_files]
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(current_frames)} å¸§å›¾åƒï¼ˆæŒ‰æ–‡ä»¶åè‡ªç„¶æ’åºï¼‰")
    for i, frame in enumerate(current_frames, 1):
        print(f"   Frame {i}: {Path(frame).name}")
    
    return True

def show_current_frames():
    """æ˜¾ç¤ºå½“å‰åŠ è½½çš„å›¾åƒå¸§"""
    if not current_frames:
        print("ğŸ“­ å½“å‰æ²¡æœ‰åŠ è½½ä»»ä½•å›¾åƒå¸§")
        return
    
    print(f"\nğŸ“· å½“å‰åŠ è½½çš„å›¾åƒå¸§ (å…± {len(current_frames)} å¸§):")
    for i, frame in enumerate(current_frames, 1):
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        exists = "âœ…" if os.path.exists(frame) else "âŒ"
        print(f"   {i}. {exists} {Path(frame).name}")
        print(f"      è·¯å¾„: {frame}")

def manage_history():
    """ç®¡ç†å¯¹è¯å†å²ï¼Œå®ç°é—å¿˜æœºåˆ¶"""
    global conversation_history
    
    # ç­–ç•¥1: æŒ‰è½®æ•°æˆªæ–­
    if len(conversation_history) > MAX_HISTORY_TURNS * 2:
        conversation_history = conversation_history[-(MAX_HISTORY_TURNS * 2):]
        print(f"ğŸ’¡ æç¤º: å¯¹è¯å†å²å·²è¶…è¿‡{MAX_HISTORY_TURNS}è½®ï¼Œè‡ªåŠ¨æ¸…ç†äº†æ—©æœŸå¯¹è¯\n")
    
    # ç­–ç•¥2: æŒ‰tokenæ•°æˆªæ–­ï¼ˆåŒ…æ‹¬å›¾åƒï¼‰
    total_text = ""
    image_count = 0
    for msg in conversation_history:
        for content in msg["content"]:
            if content["type"] == "text":
                total_text += content["text"]
            elif content["type"] == "image":
                image_count += 1
    
    # ä¼°ç®—ï¼šæ–‡æœ¬token + å›¾åƒtokenï¼ˆæ¯å¼ å›¾çº¦256 tokenï¼‰
    estimated_tokens = len(total_text) * 1.5 + image_count * 256
    
    while estimated_tokens > MAX_TOKENS and len(conversation_history) > 2:
        removed = conversation_history[:2]
        conversation_history = conversation_history[2:]
        
        removed_text = ""
        removed_images = 0
        for msg in removed:
            for content in msg["content"]:
                if content["type"] == "text":
                    removed_text += content["text"]
                elif content["type"] == "image":
                    removed_images += 1
        
        estimated_tokens -= (len(removed_text) * 1.5 + removed_images * 256)

def generate_response_with_frames(user_input):
    """ç”Ÿæˆå¸¦å›¾åƒå¸§çš„æ¨¡å‹å›å¤"""
    if not current_frames:
        print("âš ï¸  æç¤º: å½“å‰æ²¡æœ‰åŠ è½½å›¾åƒå¸§ï¼Œè¯·å…ˆä½¿ç”¨ 'load <ç›®å½•>' å‘½ä»¤åŠ è½½å›¾åƒ")
        return None
    
    # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆå›¾åƒ + æ–‡æœ¬ï¼‰
    user_content = []
    
    # æ·»åŠ æ‰€æœ‰å›¾åƒå¸§ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
    for frame_path in current_frames:
        user_content.append({
            "type": "image",
            "image": f"file://{frame_path}"
        })
    
    # æ·»åŠ ç”¨æˆ·æ–‡æœ¬
    user_content.append({
        "type": "text",
        "text": user_input
    })
    
    # æ·»åŠ åˆ°å†å²
    conversation_history.append({
        "role": "user",
        "content": user_content
    })
    
    # æ‰§è¡Œé—å¿˜æœºåˆ¶
    manage_history()
    
    try:
        # å¤„ç†è¾“å…¥
        text = processor.apply_chat_template(
            conversation_history,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # æ³¨æ„ï¼šå¯¹äºå›¾åƒè¾“å…¥ï¼Œéœ€è¦ä¼ é€’ images å‚æ•°
        inputs = processor(
            text=[text],
            images=[Image.open(frame) for frame in current_frames],
            return_tensors="pt",
        ).to(model.device)
        
        # ç”Ÿæˆå›å¤
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.8,
            repetition_penalty=1.05
        )
        
        # è§£ç è¾“å‡º
        generated_ids_trimmed = [
            out_ids[len(in_ids):]
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
        conversation_history.append({
            "role": "assistant",
            "content": [
                {"type": "text", "text": output_text}
            ]
        })
        
        return output_text
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
        # ç§»é™¤å¤±è´¥çš„ç”¨æˆ·æ¶ˆæ¯
        if conversation_history and conversation_history[-1]["role"] == "user":
            conversation_history.pop()
        return None

def generate_text_only_response(user_input):
    """ç”Ÿæˆçº¯æ–‡æœ¬å›å¤ï¼ˆä¸å¸¦å›¾åƒï¼‰"""
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    conversation_history.append({
        "role": "user",
        "content": [
            {"type": "text", "text": user_input}
        ]
    })
    
    manage_history()
    
    try:
        text = processor.apply_chat_template(
            conversation_history,
            tokenize=False,
            add_generation_prompt=True
        )
        inputs = processor(
            text=[text],
            return_tensors="pt",
        ).to(model.device)
        
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.8,
            repetition_penalty=1.05
        )
        
        generated_ids_trimmed = [
            out_ids[len(in_ids):]
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        conversation_history.append({
            "role": "assistant",
            "content": [
                {"type": "text", "text": output_text}
            ]
        })
        
        return output_text
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
        if conversation_history and conversation_history[-1]["role"] == "user":
            conversation_history.pop()
        return None

# å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½å›¾åƒå¸§
if load_frames_from_directory(FRAMES_DIRECTORY):
    print("\n" + "=" * 70)
    print("æ¬¢è¿ä½¿ç”¨ Qwen3-VL è§†é¢‘å¸§åºåˆ—å¯¹è¯ç³»ç»Ÿ!")
    print("=" * 70)
    print("ğŸ“ å‘½ä»¤è¯´æ˜:")
    print("  - 'reload'         : é‡æ–°åŠ è½½å›¾åƒå¸§")
    print("  - 'show'           : æ˜¾ç¤ºå½“å‰å·²åŠ è½½çš„å›¾åƒå¸§")
    print("  - 'clear'          : æ¸…ç©ºå¯¹è¯å†å²")
    print("  - 'status'         : æŸ¥çœ‹çŠ¶æ€")
    print("  - 'exit/quit/q'    : é€€å‡ºç¨‹åº")
    print("=" * 70)
    print("\nğŸ¤– åŠ©æ‰‹: ä½ å¥½ï¼æˆ‘å·²ç»åŠ è½½äº†å›¾åƒåºåˆ—ï¼Œå¯ä»¥å¼€å§‹æé—®äº†ã€‚\n")
else:
    print("\n" + "=" * 70)
    print("âš ï¸  è­¦å‘Š: å›¾åƒå¸§åŠ è½½å¤±è´¥")
    print(f"è¯·æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨: {FRAMES_DIRECTORY}")
    print("ä½ ä»ç„¶å¯ä»¥è¿›è¡Œçº¯æ–‡æœ¬å¯¹è¯")
    print("=" * 70)
    print("\nğŸ¤– åŠ©æ‰‹: ä½ å¥½ï¼è™½ç„¶å›¾åƒåŠ è½½å¤±è´¥ï¼Œä½†æˆ‘ä»å¯ä»¥å¸®ä½ ã€‚\n")

# ä¸»å¯¹è¯å¾ªç¯
while True:
    try:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("ğŸ‘¤ ä½ : ").strip()
        
        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower() in ['exit', 'quit', 'q']:
            print("\nå†è§ï¼ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼ğŸ‘‹")
            break
        
        # é‡æ–°åŠ è½½å›¾åƒå¸§
        if user_input.lower() == 'reload':
            print("\né‡æ–°åŠ è½½å›¾åƒå¸§...")
            load_frames_from_directory(FRAMES_DIRECTORY)
            continue
        
        # æ˜¾ç¤ºå½“å‰å›¾åƒå¸§
        if user_input.lower() == 'show':
            show_current_frames()
            continue
        
        # æ¸…ç©ºå¯¹è¯å†å²
        if user_input.lower() == 'clear':
            conversation_history = []
            print("\nâœ… å¯¹è¯å†å²å·²æ¸…ç©ºï¼\n")
            continue
        
        # æ˜¾ç¤ºçŠ¶æ€
        if user_input.lower() == 'status':
            turns = len(conversation_history) // 2
            print(f"\nğŸ“Š å½“å‰çŠ¶æ€:")
            print(f"   - å¯¹è¯è½®æ•°: {turns}")
            print(f"   - å†å²æ¶ˆæ¯æ•°: {len(conversation_history)}")
            print(f"   - æœ€å¤§ä¿ç•™è½®æ•°: {MAX_HISTORY_TURNS}")
            print(f"   - å·²åŠ è½½å›¾åƒå¸§: {len(current_frames)}")
            print(f"   - æœ€å¤§å¸§æ•°: {MAX_FRAMES}\n")
            continue
        
        # è·³è¿‡ç©ºè¾“å…¥
        if not user_input:
            continue
        
        # ç”Ÿæˆå›å¤
        print("\nğŸ¤– åŠ©æ‰‹: ", end="", flush=True)
        
        if current_frames:
            # å¸¦å›¾åƒçš„æ¨ç†
            response = generate_response_with_frames(user_input)
        else:
            # çº¯æ–‡æœ¬å¯¹è¯
            response = generate_text_only_response(user_input)
        
        if response:
            print(response + "\n")
        
    except KeyboardInterrupt:
        print("\n\næ£€æµ‹åˆ°ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
        break
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}\n")
        import traceback
        traceback.print_exc()
