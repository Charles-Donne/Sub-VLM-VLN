import torch
import os
import re
from pathlib import Path
from transformers import AutoModelForImageTextToText, AutoProcessor
from PIL import Image

def natural_sort_key(text):
    """è‡ªç„¶æ’åºï¼šæ­£ç¡®å¤„ç†æ•°å­—ï¼ˆ1, 2, 10 è€Œä¸æ˜¯ 1, 10, 2ï¼‰"""
    return [int(c) if c.isdigit() else c.lower() for c in re.split('([0-9]+)', str(text))]

# æœ¬åœ°æ¨¡å‹è·¯å¾„
MODEL_PATH = "/root/autodl-tmp/Qwen3-VL-8B-Instruct"

# å›ºå®šçš„å›¾åƒå¸§ç›®å½•ï¼ˆä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰
FRAMES_DIRECTORY = "/root/autodl-tmp/video_frames"

# å†å²ç®¡ç†é…ç½®
MAX_FRAMES = 8          # å•æ¬¡æœ€å¤šå¤„ç†8å¸§å›¾åƒ

# 1. åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
model = AutoModelForImageTextToText.from_pretrained(
    MODEL_PATH,
    device_map="auto",
    dtype="auto",
)
processor = AutoProcessor.from_pretrained(MODEL_PATH)
print("æ¨¡å‹åŠ è½½å®Œæˆ!")

# è‡ªåŠ¨åŠ è½½å›¾åƒå¸§
print("\næ­£åœ¨ä»å›ºå®šç›®å½•åŠ è½½å›¾åƒå¸§...")
print(f"ç›®å½•: {FRAMES_DIRECTORY}")

# å›¾åƒå¸§åˆ—è¡¨
current_frames = []  # å­˜å‚¨å½“å‰åŠ è½½çš„å›¾åƒè·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰

def load_frames_from_directory(directory_path):
    """ä»ç›®å½•åŠ è½½å›¾åƒå¸§ï¼ŒæŒ‰æ–‡ä»¶åæ’åº"""
    global current_frames
    
    if not os.path.exists(directory_path):
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        return False
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'}
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = []
    for file in Path(directory_path).iterdir():
        if file.suffix.lower() in image_extensions:
            image_files.append(file)
    
    if not image_files:
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return False
    
    # æŒ‰æ–‡ä»¶åè‡ªç„¶æ’åºï¼ˆæ­£ç¡®å¤„ç†æ•°å­—ï¼š1, 2, 10 è€Œä¸æ˜¯ 1, 10, 2ï¼‰
    image_files.sort(key=lambda x: natural_sort_key(x.name))
    
    # é™åˆ¶å¸§æ•°
    if len(image_files) > MAX_FRAMES:
        print(f"âš ï¸  è­¦å‘Š: å‘ç° {len(image_files)} å¸§ï¼ŒåªåŠ è½½æœ€è¿‘çš„ {MAX_FRAMES} å¸§")
        image_files = image_files[-MAX_FRAMES:]
    
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„å­—ç¬¦ä¸²
    current_frames = [str(file.absolute()) for file in image_files]
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(current_frames)} å¸§å›¾åƒï¼ˆæŒ‰æ–‡ä»¶åè‡ªç„¶æ’åºï¼‰")
    for i, frame in enumerate(current_frames, 1):
        print(f"   Frame {i}: {Path(frame).name}")
    
    return True

def show_current_frames():
    """æ˜¾ç¤ºå½“å‰åŠ è½½çš„å›¾åƒå¸§"""
    if not current_frames:
        print("ğŸ“­ å½“å‰æ²¡æœ‰åŠ è½½ä»»ä½•å›¾åƒå¸§")
        return
    
    print(f"\nğŸ“· å½“å‰åŠ è½½çš„å›¾åƒå¸§ (å…± {len(current_frames)} å¸§):")
    for i, frame in enumerate(current_frames, 1):
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        exists = "âœ…" if os.path.exists(frame) else "âŒ"
        print(f"   {i}. {exists} {Path(frame).name}")
        print(f"      è·¯å¾„: {frame}")

def generate_response_with_frames(user_input):
    """ç”Ÿæˆå¸¦å›¾åƒå¸§çš„æ¨¡å‹å›å¤ï¼ˆå•æ¬¡æ¨ç†ï¼Œæ— å†å²ï¼‰"""
    if not current_frames:
        print("âš ï¸  æç¤º: å½“å‰æ²¡æœ‰åŠ è½½å›¾åƒå¸§")
        return None
    
    # æ„å»ºå•æ¬¡æ¶ˆæ¯ï¼ˆå›¾åƒ + æ–‡æœ¬ï¼‰
    user_content = []
    
    # æ·»åŠ æ‰€æœ‰å›¾åƒå¸§
    for frame_path in current_frames:
        user_content.append({
            "type": "image",
            "image": f"file://{frame_path}"
        })
    
    # æ·»åŠ ç”¨æˆ·æ–‡æœ¬
    user_content.append({
        "type": "text",
        "text": user_input
    })
    
    # å•æ¬¡å¯¹è¯æ¶ˆæ¯
    messages = [{
        "role": "user",
        "content": user_content
    }]
    
    try:
        # å¤„ç†è¾“å…¥
        text = processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # åŠ è½½æ‰€æœ‰å›¾åƒ
        images = []
        for frame in current_frames:
            try:
                img = Image.open(frame)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                images.append(img)
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½å›¾åƒ {frame}: {e}")
        
        if not images:
            print("âŒ é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾åƒ")
            return None
        
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: åŠ è½½äº† {len(images)} å¼ å›¾åƒ")
        for i, img in enumerate(images, 1):
            print(f"   å›¾åƒ {i}: å°ºå¯¸={img.size}, æ¨¡å¼={img.mode}")
        
        inputs = processor(
            text=[text],
            images=images,
            return_tensors="pt",
            padding=True,
        ).to(model.device)
        
        # ç”Ÿæˆå›å¤
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.8,
            repetition_penalty=1.05
        )
        
        # è§£ç è¾“å‡º
        generated_ids_trimmed = [
            out_ids[len(in_ids):]
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        return output_text
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_text_only_response(user_input):
    """ç”Ÿæˆçº¯æ–‡æœ¬å›å¤ï¼ˆå•æ¬¡æ¨ç†ï¼Œæ— å†å²ï¼‰"""
    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": user_input}
        ]
    }]
    
    try:
        text = processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        inputs = processor(
            text=[text],
            return_tensors="pt",
            padding=True,
        ).to(model.device)
        
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.8,
            repetition_penalty=1.05
        )
        
        generated_ids_trimmed = [
            out_ids[len(in_ids):]
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        return output_text
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

# å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½å›¾åƒå¸§
if load_frames_from_directory(FRAMES_DIRECTORY):
    print("\n" + "=" * 70)
    print("æ¬¢è¿ä½¿ç”¨ Qwen3-VL è§†é¢‘å¸§åºåˆ—å¯¹è¯ç³»ç»Ÿ!")
    print("=" * 70)
    print("ğŸ“ å‘½ä»¤è¯´æ˜:")
    print("  - 'reload'         : é‡æ–°åŠ è½½å›¾åƒå¸§")
    print("  - 'show'           : æ˜¾ç¤ºå½“å‰å·²åŠ è½½çš„å›¾åƒå¸§")
    print("  - 'exit/quit/q'    : é€€å‡ºç¨‹åº")
    print("ğŸ’¡ æ¯æ¬¡éƒ½æ˜¯ç‹¬ç«‹æ¨ç†ï¼Œä¸ä¿ç•™å¯¹è¯å†å²")
    print("=" * 70)
    print("\nğŸ¤– åŠ©æ‰‹: ä½ å¥½ï¼æˆ‘å·²ç»åŠ è½½äº†å›¾åƒåºåˆ—ï¼Œå¯ä»¥å¼€å§‹æé—®äº†ã€‚\n")
else:
    print("\n" + "=" * 70)
    print("âš ï¸  è­¦å‘Š: å›¾åƒå¸§åŠ è½½å¤±è´¥")
    print(f"è¯·æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨: {FRAMES_DIRECTORY}")
    print("ä½ ä»ç„¶å¯ä»¥è¿›è¡Œçº¯æ–‡æœ¬å¯¹è¯")
    print("=" * 70)
    print("\nğŸ¤– åŠ©æ‰‹: ä½ å¥½ï¼è™½ç„¶å›¾åƒåŠ è½½å¤±è´¥ï¼Œä½†æˆ‘ä»å¯ä»¥å¸®ä½ ã€‚\n")

# ä¸»å¯¹è¯å¾ªç¯
while True:
    try:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("ğŸ‘¤ ä½ : ").strip()
        
        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower() in ['exit', 'quit', 'q']:
            print("\nå†è§ï¼ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼ğŸ‘‹")
            break
        
        # é‡æ–°åŠ è½½å›¾åƒå¸§
        if user_input.lower() == 'reload':
            print("\né‡æ–°åŠ è½½å›¾åƒå¸§...")
            load_frames_from_directory(FRAMES_DIRECTORY)
            continue
        
        # æ˜¾ç¤ºå½“å‰å›¾åƒå¸§
        if user_input.lower() == 'show':
            show_current_frames()
            continue
        
        # è·³è¿‡ç©ºè¾“å…¥
        if not user_input:
            continue
        
        # ç”Ÿæˆå›å¤
        print("\nğŸ¤– åŠ©æ‰‹: ", end="", flush=True)
        
        if current_frames:
            # å¸¦å›¾åƒçš„æ¨ç†
            response = generate_response_with_frames(user_input)
        else:
            # çº¯æ–‡æœ¬å¯¹è¯
            response = generate_text_only_response(user_input)
        
        if response:
            print(response + "\n")
        
    except KeyboardInterrupt:
        print("\n\næ£€æµ‹åˆ°ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
        break
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}\n")
        import traceback
        traceback.print_exc()
